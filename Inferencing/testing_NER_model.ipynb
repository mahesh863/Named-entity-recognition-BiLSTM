{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testing_NER_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNJs9IQ1c6dL"
      },
      "source": [
        "#Model Weights\n",
        "!cp \"/content/drive/MyDrive/models/NER/NER.h5\" \"./\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI9HLCIvn8He"
      },
      "source": [
        "#Tokenizer\n",
        "!cp \"/content/drive/MyDrive/models/NER/ner_tokenizer.json\" \"./\"\n",
        "!cp \"/content/drive/MyDrive/models/NER/txt_tokenizer.json\" \"./\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWw4DHCTdLeY"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, TimeDistributed, Dense\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwr0a6B_fpn9"
      },
      "source": [
        "# Recreating the model\n",
        "def build_model_bilstm(vocab_size, embedding_dim, rnn_units, batch_size, classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        Embedding(vocab_size, embedding_dim, mask_zero=True,\n",
        "                  batch_input_shape=[batch_size,None]),\n",
        "        Bidirectional(LSTM(units=rnn_units,\n",
        "                           return_sequences=True)),\n",
        "        TimeDistributed(Dense(rnn_units, activation='relu')),\n",
        "        Dense(num_classes, activation=\"softmax\")\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Kja2sOWh8Es"
      },
      "source": [
        "# Loading the NER tokenizer\n",
        "with open('ner_tokenizer.json') as f:\n",
        "  data = json.load(f)\n",
        "  ner_tokenizer = tokenizer_from_json(data)\n",
        "\n",
        "# Loading the text tokenizer tokenizer\n",
        "with open('txt_tokenizer.json') as f:\n",
        "  data = json.load(f)\n",
        "  txt_tokenizer = tokenizer_from_json(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZyxPrtRln-F"
      },
      "source": [
        "ner_config = ner_tokenizer.get_config() \n",
        "txt_config = txt_tokenizer.get_config()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6SMvaRKmQZ2"
      },
      "source": [
        "ner_vocab = eval(ner_config[\"word_index\"]) # NER Vocabulary\n",
        "txt_vocab = eval(txt_config[\"word_index\"]) # Text Vocabulary"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GouWm3BuofUC"
      },
      "source": [
        "# Mode config\n",
        "vocab_size = len(txt_vocab) + 1\n",
        "embedding_dim = 64\n",
        "rnn_units = 100\n",
        "BATCH_SIZE=1\n",
        "num_classes = len(ner_vocab) + 1\n",
        "\n",
        "# Building the model\n",
        "model = build_model_bilstm(\n",
        "    vocab_size = vocab_size,\n",
        "    embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE,\n",
        "    classes=num_classes)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y21IELKOhOrg"
      },
      "source": [
        "model.load_weights(\"NER.h5\") #Loading the model weight"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTtHx8Fa6qse"
      },
      "source": [
        "# Getting the keys and values of from the vocabulary for conversion of model prediction to more readable format.\n",
        "ner_keys = list(ner_vocab.keys())\n",
        "ner_values = list(ner_vocab.values())\n",
        "\n",
        "def get_result(result):\n",
        "  result_index = []\n",
        "  actual_result = []\n",
        "  for i in range(result.shape[1]):\n",
        "    ner_pred = np.argmax(result[0][i])\n",
        "    result_index.append(ner_pred)\n",
        "  for r in result_index:\n",
        "    pos = ner_values.index(r)\n",
        "    actual_result.append(ner_keys[pos])\n",
        "  return actual_result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "859Gec2_oj55",
        "outputId": "4300d5de-eb51-40ea-9544-979a4ce8c8de"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (1, None, 64)             2523072   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (1, None, 200)           132000    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (1, None, 100)           20100     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (1, None, 19)             1919      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,677,091\n",
            "Trainable params: 2,677,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Irc-UhcCq7eQ"
      },
      "source": [
        "# Preprocessing text before feeding it to the model\n",
        "def preprocess_text(sent):\n",
        "  sent = sent.split(\" \")\n",
        "  tokenized= txt_tokenizer.texts_to_sequences(sent)\n",
        "  tokenized_arr = []\n",
        "  for i in tokenized:\n",
        "    tokenized_arr.append(i[0])\n",
        "  return np.array(tokenized_arr).reshape(1, len(tokenized_arr))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PceFEVcZU5ED"
      },
      "source": [
        "# Feeding the text to model and getting the prediction and cleaning the results.\n",
        "def make_prediction(text, model= model):\n",
        "  text= text\n",
        "  tokenized_text = preprocess_text(text)\n",
        "  result= model.predict(tokenized_text)\n",
        "  pred = get_result(result)\n",
        "  return pred"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6T1dY0_7FtG"
      },
      "source": [
        "## Testing the model with different  inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QUu06hgpqhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc704ce-8000-4c8f-d88f-555ab9efe8ee"
      },
      "source": [
        "text = \"I want to visit New York\"\n",
        "make_prediction(text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'O', 'O', 'O', 'B-geo', 'I-geo']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v03AG_5kzGkX"
      },
      "source": [
        "The model was able to detect that New York as a \"Geographical\" Location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8LS0Gctw_hC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ca00908-7113-40b7-a61d-1d5a74c243fa"
      },
      "source": [
        "text2 = \"My name is Mahesh\"\n",
        "make_prediction(text2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'O', 'O', 'B-per']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-MQd6kHzbmn"
      },
      "source": [
        "The model was able to detect Mahesh as a \"Person\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFr_0N0g0jWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "672ea94c-f9fb-42cd-fe5a-6ed21d1b323c"
      },
      "source": [
        "text3 = \"Apple is a big company.\"\n",
        "make_prediction(text3)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-org', 'O', 'O', 'O', 'B-org']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLtxtOgOzp3k"
      },
      "source": [
        "The model was able to detect \"Apple\" as an \"Organization\". Also, it classified  \"Company\" as an \"Organization\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho4m_d761Oeh",
        "outputId": "92588b88-5a75-44c9-e8ac-0b6be2b1d4bb"
      },
      "source": [
        "text4 = \"I ordered lights from Amazon\"\n",
        "make_prediction(text4)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'O', 'O', 'O', 'B-org']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOxCDjJi0OUe"
      },
      "source": [
        "The model was able to detect \"Amazon\" as an \"Organization\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVdOiugHUTHK",
        "outputId": "3911f7a0-332a-4743-e8dc-7b2a47aeaa52"
      },
      "source": [
        "text5 = \"Meet me in the morning\"\n",
        "make_prediction(text5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'O', 'O', 'O', 'B-tim']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5rGEf300TL2"
      },
      "source": [
        "The model was able to detect \"morning\" as an \"Time\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_PYzyylxK8u",
        "outputId": "54ae4001-d8f9-4468-f064-3142a64ae7e2"
      },
      "source": [
        "text6 = \"Jeff would you like to have some coffee?\"\n",
        "make_prediction(text6)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imUkuXpV0YHo"
      },
      "source": [
        "The model was able to detect \"Jeff\" as an \"Person\""
      ]
    }
  ]
}